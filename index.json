[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536476400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536476400,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://vidhishanair.github.io/tutorial/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa2f8256064e29f2b3aec489c007f79a","permalink":"https://vidhishanair.github.io/experience/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/experience/","section":"experience","summary":"","tags":null,"title":"Experience","type":"experience"},{"authors":[],"categories":null,"content":"","date":1650092400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650092400,"objectID":"1a17eada47898ad460e4dd857d702bec","permalink":"https://vidhishanair.github.io/talk/transf/","publishdate":"2022-04-16T00:00:00-07:00","relpermalink":"/talk/transf/","section":"talk","summary":"","tags":[],"title":"Self Attention and Transformers for Undergrad NLP","type":"talk"},{"authors":null,"categories":null,"content":"Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods. We propose and analyze a simple, model-agnostic approach for incorporating KB paths into text-based QA systems and establish a strong upper bound on FQ for our method using an oracle retriever. We show that several variants of Personalized PageRank based fact retrievers lead to a low recall of answer entities and consequently fail to improve QA performance. Our results suggest that fact retrieval is a bottleneck for integrating KBs into real world QA datasets\n","date":1623308400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623308400,"objectID":"e59b88d52a9d855d62ced0520a25bae4","permalink":"https://vidhishanair.github.io/project/fatnq/","publishdate":"2021-06-10T00:00:00-07:00","relpermalink":"/project/fatnq/","section":"project","summary":"Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods.","tags":["KBQA","Natural Questions"],"title":"Investigating the Effect of Background Knowledge on Natural Questions","type":"project"},{"authors":[],"categories":null,"content":"","date":1622530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622530800,"objectID":"8886aec613285aec469dfc0b51192c4c","permalink":"https://vidhishanair.github.io/talk/realm/","publishdate":"2021-06-01T00:00:00-07:00","relpermalink":"/talk/realm/","section":"talk","summary":"Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it. Our best model, REALM++, incorporates all the best working findings and achieves significant QA accuracy improvements over baselines (~5.5% absolute accuracy) without any model design changes. Additionally, REALM++ matches the performance of large Open Domain QA models which have 3x more parameters demonstrating the efficiency of the setup.","tags":[],"title":"Simple and Efficient ways to Improve REALM","type":"talk"},{"authors":["Vidhisha Balachandran","Artidoro Pagnoni","Jay Yoon Lee","Dheeraj Rajagopal","Jaime Carbonell","Yulia Tsvetkov"],"categories":null,"content":"","date":1619852400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619852400,"objectID":"1d3b982d3c6ecfea72a025c5b6cefce4","permalink":"https://vidhishanair.github.io/publication/structsum/","publishdate":"2021-05-01T00:00:00-07:00","relpermalink":"/publication/structsum/","section":"publication","summary":"","tags":[],"title":"StructSum: Summarization via Structured Representations","type":"publication"},{"authors":[],"categories":null,"content":"","date":1619766000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619766000,"objectID":"646f78193515f21daf722588107b8bfe","permalink":"https://vidhishanair.github.io/talk/transp_summ/","publishdate":"2021-04-30T00:00:00-07:00","relpermalink":"/talk/transp_summ/","section":"talk","summary":"Internet users today have access to an ocean of information via the Web ranging from news articles to blogs to textbooks. To consume this ever-growing pool of information, the need for tools to concisely and accurately summarize important content from these sources is urgent. As data-driven NLP tools for automatic summarization are increasingly deployed as primary mediums for information consumption, they also become ripe for misuse by inadvertently propagating factual inaccuracies and overfitting to spurious data artifacts. Our work aims to build transparent and reliable tools for automatic summarization. This talk presents novel work toward building such methodologies. I will first introduce StructSum, an interpretable summarization framework that leverages the narrative structure of the document for producing higher quality summaries with reduced reliance on dataset artifacts. I will then present FRANK, a fine-grained factuality-focused evaluation benchmark that uses a  linguistically motivated typology to elicit human annotations on factual errors made by many state-of-art summarization models. We present a two-fold analysis: (i) we analyze various summarization models and present their strengths and weaknesses in producing factually consistent summaries and (ii) we test recent metrics proposed to evaluate factuality and present a fine-grained understanding of what kinds of errors they detect well. Finally, I will conclude with some thoughts on future directions of our work and the field of automatic summarization.","tags":[],"title":"On the Transparency and Reliability of Automatic Summarization","type":"talk"},{"authors":null,"categories":null,"content":"Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations, we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgment as well as their specific strengths and weaknesses.\n","date":1619506800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619506800,"objectID":"4e5bfc9ea7abab733901aa9adef0e5ec","permalink":"https://vidhishanair.github.io/project/frank/","publishdate":"2021-04-27T00:00:00-07:00","relpermalink":"/project/frank/","section":"project","summary":"Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets.","tags":["Summarization","Factuality","Typology Framework","Metrics"],"title":"Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics","type":"project"},{"authors":["Artidoro Pagnoni","Vidhisha Balachandran","Yulia Tsvetkov"],"categories":null,"content":"","date":1619506800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619506800,"objectID":"32b49c423a162b4abca999e5ee2cdea4","permalink":"https://vidhishanair.github.io/publication/frank/","publishdate":"2021-04-27T00:00:00-07:00","relpermalink":"/publication/frank/","section":"publication","summary":"","tags":[],"title":"Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics","type":"publication"},{"authors":["Dheeraj Rajagopal","Vidhisha Balachandran","Eduard Hovy","Yulia Tsvetkov"],"categories":null,"content":"","date":1619161200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619161200,"objectID":"9e87a192a5ffcd2608a64c2dde008c17","permalink":"https://vidhishanair.github.io/publication/selfexplain/","publishdate":"2021-04-23T00:00:00-07:00","relpermalink":"/publication/selfexplain/","section":"publication","summary":"","tags":[],"title":"SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers","type":"publication"},{"authors":null,"categories":null,"content":"Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it. Our best model, REALM++, incorporates all the best working findings and achieves significant QA accuracy improvements over baselines (~5.5% absolute accuracy) without any model design changes. Additionally, REALM++ matches the performance of large Open Domain QA models which have 3x more parameters demonstrating the efficiency of the setup.\n","date":1618729200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618729200,"objectID":"a548688b5a70880ef052837f912c7653","permalink":"https://vidhishanair.github.io/project/realm/","publishdate":"2021-04-18T00:00:00-07:00","relpermalink":"/project/realm/","section":"project","summary":"Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it.","tags":["Open Domain QA","Evaluation","REALM"],"title":"Simple and Efficient ways to Improve REALM","type":"project"},{"authors":null,"categories":null,"content":"We introduce SelfExplain, a novel self-explaining framework that explains a text classifier\u0026rsquo;s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance. Most importantly, explanations from SelfExplain are perceived as more understandable, adequately justifying and trustworthy by human judges compared to existing widely-used baselines.\n","date":1616482800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616482800,"objectID":"297097d430af9942fa1de0fac97602f5","permalink":"https://vidhishanair.github.io/project/selfexplain/","publishdate":"2021-03-23T00:00:00-07:00","relpermalink":"/project/selfexplain/","section":"project","summary":"We introduce SelfExplain, a novel self-explaining framework that explains a text classifier\u0026rsquo;s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance.","tags":["Interpretability by Design","Self-Explaining Architectures","Text Classification"],"title":"SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers","type":"project"},{"authors":["Vidhisha Balachandran","Ashish Vaswani","Yulia Tsvetkov","Niki Parmar"],"categories":null,"content":"","date":1616050800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616050800,"objectID":"28732bbac54d5e94eb58e5434d3654e0","permalink":"https://vidhishanair.github.io/publication/realm/","publishdate":"2021-03-18T00:00:00-07:00","relpermalink":"/publication/realm/","section":"publication","summary":"","tags":[],"title":"Simple and Efficient ways to Improve REALM","type":"publication"},{"authors":["Vidhisha Balachandran","Bhuwan Dhingra","Haitian Sun","Michael Collins","William Cohen"],"categories":null,"content":"","date":1615363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615363200,"objectID":"5b662861b58d024192145ef3070c3cb6","permalink":"https://vidhishanair.github.io/publication/fatnq/","publishdate":"2021-03-10T00:00:00-08:00","relpermalink":"/publication/fatnq/","section":"publication","summary":"","tags":[],"title":"Investigating the Effect of Background Knowledge on Natural Questions","type":"publication"},{"authors":null,"categories":null,"content":"To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context. Our graph-based method outperforms prior state-of-the-art negotiation models both in the accuracy of strategy/dialogue act prediction and in the quality of downstream dialogue response generation. We qualitatively show further benefits of learned strategy-graphs in providing explicit associations between effective negotiation strategies over the course of the dialogue, leading to interpretable and strategic dialogues.\n","date":1601276400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601276400,"objectID":"abd334ff702d43dd62bf8a23cd914cd7","permalink":"https://vidhishanair.github.io/project/dialograph/","publishdate":"2020-09-28T00:00:00-07:00","relpermalink":"/project/dialograph/","section":"project","summary":"To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context.","tags":["Negotiation Dialog","Graph Neural Networks","Interpretability"],"title":"DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues","type":"project"},{"authors":["Rishabh Joshi","Vidhisha Balachandran","Shikhar Vashishth","Alan Black","Yulia Tsvetkov"],"categories":null,"content":"","date":1601276400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601276400,"objectID":"2449c489a268a7f196ffbf8608805ef1","permalink":"https://vidhishanair.github.io/publication/dialograph/","publishdate":"2020-09-28T00:00:00-07:00","relpermalink":"/publication/dialograph/","section":"publication","summary":"","tags":[],"title":"DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues","type":"publication"},{"authors":null,"categories":null,"content":"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations. This module is differentiable, so the full system can be trained completely end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the index mention encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. DrKIT is also very efficient, processing upto 10x more queries per second than existing state-of-the-art QA systems.\n","date":1576224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576224000,"objectID":"e1a7127e7d74ffe9de53260fc4a625bb","permalink":"https://vidhishanair.github.io/project/vkb/","publishdate":"2019-12-13T00:00:00-08:00","relpermalink":"/project/vkb/","section":"project","summary":"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations.","tags":["Question Answering","Multi-Hop QA","Deep Learning","Knowledge Bases","Information Extraction","Data Structures for QA"],"title":"Differentiable Reasoning over a Virtual Knowledge Base","type":"project"},{"authors":null,"categories":null,"content":"","date":1551513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551513600,"objectID":"be216eba72bdfd73641f42586edd3781","permalink":"https://vidhishanair.github.io/project/entity/","publishdate":"2019-03-02T00:00:00-08:00","relpermalink":"/project/entity/","section":"project","summary":"Developing models for entity recognition and entity linking for closed domain data. Building classifiers to learn and predict cases of fraud in the insurance domain. Developing machine learning models for fraud detection in a low resource domain","tags":[],"title":"Closed Domain Entity Recognition and Fraud Detection","type":"project"},{"authors":["Bhuwan Dhingra","Manzhil Zaheer","Vidhisha Balachandran","Graham Neubig","Ruslan Salakhutdinov","William Cohen"],"categories":null,"content":"","date":1541055600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541055600,"objectID":"743fb1c33df1b57da503114683ea4a6e","permalink":"https://vidhishanair.github.io/publication/diffindex/","publishdate":"2018-11-01T00:00:00-07:00","relpermalink":"/publication/diffindex/","section":"publication","summary":"","tags":[],"title":"Differentiable Reasoning over a Virtual Knowledge Base","type":"publication"},{"authors":["Vidhisha Balachandran","Dheeraj Rajagopal","Rose Catherine","William Cohen"],"categories":null,"content":"","date":1541055600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541055600,"objectID":"60e1382df5f64dbb888d1e0f8ae5c90e","permalink":"https://vidhishanair.github.io/publication/defgen/","publishdate":"2018-11-01T00:00:00-07:00","relpermalink":"/publication/defgen/","section":"publication","summary":"","tags":[],"title":"Learning to Define Terms in the Software Domain","type":"publication"},{"authors":null,"categories":null,"content":"Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges. To this end, we propose incorporating latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. Our framework complements standard encoder-decoder summarization models by augmenting them with rich structure-aware document representations based on implicitly learned (latent) structures and externally-derived linguistic (explicit) structures. We show that our summarization framework, trained on the CNN/DM dataset, improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines.\n","date":1539327600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539327600,"objectID":"7d8671b39588934e6643cc6644f565fc","permalink":"https://vidhishanair.github.io/project/structsum/","publishdate":"2018-10-12T00:00:00-07:00","relpermalink":"/project/structsum/","section":"project","summary":"Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges.","tags":["Text Summarization","Latent/Explicit Document Structure","Interpretable Structures"],"title":"StructSum: Summarization via Structured Representations","type":"project"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536476400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536476400,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://vidhishanair.github.io/tutorial/example/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":null,"categories":null,"content":"","date":1527404400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527404400,"objectID":"0d31a0bf9f48884bbb83f4c192477fc7","permalink":"https://vidhishanair.github.io/project/tabletotext/","publishdate":"2018-05-27T00:00:00-07:00","relpermalink":"/project/tabletotext/","section":"project","summary":"Built a Seq2Seq model for generating biographies of people from Wikipedia Biography Tables. Used alignments between table and text phrases to improve biographies. Results were on par with the previous State of Art models","tags":["Table to Text Generation"],"title":"Table to Text Generation","type":"project"},{"authors":null,"categories":null,"content":"One way to test a person’s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information. Our approach improves previous baselines by 2 BLEU points for the definition generation task. Our experiments also show the additional challenges associated with the task and the short-comings of language-model based architectures for definition generation.\n","date":1512374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512374400,"objectID":"33178e6d6db0122b02e6994acbf56928","permalink":"https://vidhishanair.github.io/project/defgen/","publishdate":"2017-12-04T00:00:00-08:00","relpermalink":"/project/defgen/","section":"project","summary":"One way to test a person’s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information.","tags":["Sequence Generation","Word Embeddings"],"title":"Definition Generation","type":"project"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461135600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515830400,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://vidhishanair.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00-07:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["Dinkar Sitaram","Phalachandra, HL","Sudheendra Halwalkar","Sirushti Murugesan","Pavan Sudheendra","Rohith Ananth","Vidhisha Balachandran","Abdul Hannan Kanji","Swati Chidambar Bhat","Kruti B"],"categories":null,"content":"","date":1404198000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404198000,"objectID":"c099ad599effe86e90d5fc4314e9eb82","permalink":"https://vidhishanair.github.io/publication/cloud/","publishdate":"2014-07-01T00:00:00-07:00","relpermalink":"/publication/cloud/","section":"publication","summary":"","tags":[],"title":"Simple Cloud Federation","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://vidhishanair.github.io/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]