[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536476400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536476400,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://vidhishanair.github.io/tutorial/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa2f8256064e29f2b3aec489c007f79a","permalink":"https://vidhishanair.github.io/experience/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/experience/","section":"experience","summary":"","tags":null,"title":"Experience","type":"experience"},{"authors":null,"categories":null,"content":"Large language models (LLMs) are increasingly adopted for knowledge-intensive tasks and contexts. Existing approaches improve the knowledge capabilities of general-purpose LLMs through retrieval or generated knowledge prompting, but they fall short of reflecting two key properties of knowledge-rich models: knowledge should be modular, ever-growing, sourced from diverse domains; knowledge acquisition and production should be a collaborative process, where diverse stakeholders contribute new information. To this end, we propose CooK, a novel framework to empower general-purpose large language models with modular and collaboratively sourced knowledge. We first introduce specialized language models, autoregressive models trained on corpora from a wide range of domains and sources. These specialized LMs serve as parametric knowledge repositories that are later prompted to generate background knowledge for general-purpose LLMs. We then propose three knowledge filters to dynamically select and retain information in generated documents by controlling for relevance, brevity, and factuality. Finally, we propose bottom-up and top-down knowledge integration approaches to augment general-purpose LLMs with the curated (relevant, factual) knowledge from community-driven specialized LMs that enable multi-domain knowledge synthesis and on-demand knowledge requests. Through extensive experiments, we demonstrate that CooK achieves state-of-the-art performance on six benchmark datasets. Our results highlight the potential of enriching general-purpose LLMs with evolving and modular knowledge \u0026ndash; relevant knowledge that can be continuously updated through the collective efforts of the research community.\n","date":1684393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684393200,"objectID":"1ba6ef08f571e8402d78a16e18463cc3","permalink":"https://vidhishanair.github.io/project/cook/","publishdate":"2023-05-18T00:00:00-07:00","relpermalink":"/project/cook/","section":"project","summary":"Large language models (LLMs) are increasingly adopted for knowledge-intensive tasks and contexts. Existing approaches improve the knowledge capabilities of general-purpose LLMs through retrieval or generated knowledge prompting, but they fall short of reflecting two key properties of knowledge-rich models: knowledge should be modular, ever-growing, sourced from diverse domains; knowledge acquisition and production should be a collaborative process, where diverse stakeholders contribute new information. To this end, we propose CooK, a novel framework to empower general-purpose large language models with modular and collaboratively sourced knowledge.","tags":["Language Generation","Question Answering","Factuality","Reliable Generation","Knowledge Bases"],"title":"CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge","type":"project"},{"authors":["Shangbin Feng","Weijia Shi","Yuyang Bai","_Vidhisha Balachandran_","Tianxing He","Yulia Tsvetkov"],"categories":null,"content":"","date":1684393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684393200,"objectID":"284a35ecfabb4bc0f77a09a051027fbd","permalink":"https://vidhishanair.github.io/publication/cook/","publishdate":"2023-05-18T00:00:00-07:00","relpermalink":"/publication/cook/","section":"publication","summary":"","tags":[],"title":"CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge","type":"publication"},{"authors":null,"categories":null,"content":"Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases. We introduce three types of complementary factuality pretraining objectives based on direct entity facts, facts grounded in auxiliary knowledge about entities, and facts constructed compositionally through knowledge base walks. The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three out-of-domain scientific literature datasets. Further analysis of FactKB shows improved ability to detect erroneous entities and relations in summaries and is robust and generalizable across domains.\n","date":1684393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684393200,"objectID":"e025f86aece6c9d3e37a4593c1d1cb0a","permalink":"https://vidhishanair.github.io/project/factkb/","publishdate":"2023-05-18T00:00:00-07:00","relpermalink":"/project/factkb/","section":"project","summary":"Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases.","tags":["Text Summarization","Language Generation","Factuality","Pretraining","Reliable Generation","Knowledge Bases"],"title":"FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge","type":"project"},{"authors":["Shangbin Feng","_Vidhisha Balachandran_","Yuyang Bai","Yulia Tsvetkov"],"categories":null,"content":"","date":1684393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684393200,"objectID":"e50dca9bce0ff84555f43fc62872ea65","permalink":"https://vidhishanair.github.io/publication/factkb/","publishdate":"2023-05-18T00:00:00-07:00","relpermalink":"/publication/factkb/","section":"publication","summary":"","tags":[],"title":"FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge","type":"publication"},{"authors":[],"categories":null,"content":"","date":1684393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684393200,"objectID":"5ed648c44bcb4f8eb1532d7c9fd7b90e","permalink":"https://vidhishanair.github.io/talk/semafor/","publishdate":"2023-05-18T00:00:00-07:00","relpermalink":"/talk/semafor/","section":"talk","summary":"Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models. With this data, we train a more robust fact-correction model to post-edit the summaries to improve factual consistency. Through quantitative and qualitative experiments on two popular summarization datasets -- CNN/DM and XSum -- we show that our approach vastly outperforms prior methods in correcting erroneous summaries. Our model -- FactEdit -- improves factuality scores by over ~11 points on CNN/DM and over ~31 points on XSum on average across multiple summarization models, producing more factual summaries while maintaining competitive summarization quality.","tags":[],"title":"Generalizable Factual Error Correction of Model Generated Summaries","type":"talk"},{"authors":null,"categories":null,"content":"Recent advances in the capacity of large language models to generate human-like text have resulted in their increased adoption in user-facing settings. In parallel, these improvements have prompted a heated discourse around the risks of societal harms they introduce, whether inadvertent or malicious. Several studies have identified potential causes of these harms and called for their mitigation via development of safer and fairer models. Going beyond enumerating the risks of harms, this work provides a survey of practical methods for addressing potential threats and societal harms from language generation models. We draw on several prior works\u0026rsquo; taxonomies of language model risks to present a structured overview of strategies for detecting and ameliorating different kinds of risks/harms of language generators. Bridging diverse strands of research, this survey aims to serve as a practical guide for both LM researchers and practitioners with explanations of motivations behind different mitigation strategies, their limitations, and open problems for future research.\n","date":1674460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674460800,"objectID":"acd3763d3a29de9d7dc3cdac100c378e","permalink":"https://vidhishanair.github.io/project/harms_survey/","publishdate":"2023-01-23T00:00:00-08:00","relpermalink":"/project/harms_survey/","section":"project","summary":"Recent advances in the capacity of large language models to generate human-like text have resulted in their increased adoption in user-facing settings. In parallel, these improvements have prompted a heated discourse around the risks of societal harms they introduce, whether inadvertent or malicious. Several studies have identified potential causes of these harms and called for their mitigation via development of safer and fairer models. Going beyond enumerating the risks of harms, this work provides a survey of practical methods for addressing potential threats and societal harms from language generation models.","tags":["Social Harms","Language Generation","Factuality","Mitigation"],"title":"Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey","type":"project"},{"authors":["Sachin Kumar\\*","_Vidhisha Balachandran\\*_","Lucille Njoo","Antonios Anastasopoulos","Yulia Tsvetkov"],"categories":null,"content":"","date":1674460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674460800,"objectID":"07a4faeb71a691cb10dabd041468d413","permalink":"https://vidhishanair.github.io/publication/harms_survey/","publishdate":"2023-01-23T00:00:00-08:00","relpermalink":"/publication/harms_survey/","section":"publication","summary":"","tags":[],"title":"Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey","type":"publication"},{"authors":null,"categories":null,"content":"Keyphrase extraction aims at automatically extracting a list of ``important\u0026rdquo; phrases representing the key concepts in a document. Prior approaches for unsupervised keyphrase extraction resort to heuristic notions of phrase importance via embedding similarities or graph centrality, requiring extensive domain expertise to develop them. Our work presents an alternative operational definition: phrases that are most useful for predicting the topic of a text are keyphrases. To this end, we propose INSPECT\u0026mdash;a self-explaining neural framework for identifying influential keyphrases by measuring the predictive impact of input phrases on the downstream task of topic classification. We show that this novel approach not only alleviates the need for ad-hoc heuristics but also achieves state-of-the-art results in unsupervised keyphrase extraction in 3 out of 4 diverse datasets across two domains: scientific publications and news articles. Ultimately, our study suggests a new usage of interpretable neural networks as an intrinsic component in NLP systems, and not only as a tool for explaining model predictions to humans.\n","date":1674460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674460800,"objectID":"68690458ea4667f2fbbda3727705b3ba","permalink":"https://vidhishanair.github.io/project/inspect/","publishdate":"2023-01-23T00:00:00-08:00","relpermalink":"/project/inspect/","section":"project","summary":"Keyphrase extraction aims at automatically extracting a list of ``important\u0026rdquo; phrases representing the key concepts in a document. Prior approaches for unsupervised keyphrase extraction resort to heuristic notions of phrase importance via embedding similarities or graph centrality, requiring extensive domain expertise to develop them. Our work presents an alternative operational definition: phrases that are most useful for predicting the topic of a text are keyphrases. To this end, we propose INSPECT\u0026mdash;a self-explaining neural framework for identifying influential keyphrases by measuring the predictive impact of input phrases on the downstream task of topic classification.","tags":["Information Extraction","Interpretability","Unsupervised Objectives"],"title":"Unsupervised Keyphrase Extraction via Interpretable Neural Networks","type":"project"},{"authors":["Rishabh Joshi\\*","_Vidhisha Balachandran\\*_","Emily Saldanha","Maria Glenski","Svitlana Volkova","Yulia Tsvetkov"],"categories":null,"content":"","date":1674460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674460800,"objectID":"a7937a4412febe7651bd61a6918c7a72","permalink":"https://vidhishanair.github.io/publication/inspect/","publishdate":"2023-01-23T00:00:00-08:00","relpermalink":"/publication/inspect/","section":"publication","summary":"","tags":[],"title":"Unsupervised Keyphrase Extraction via Interpretable Neural Networks","type":"publication"},{"authors":null,"categories":null,"content":"Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models. With this data, we train a more robust fact-correction model to post-edit the summaries to improve factual consistency. Through quantitative and qualitative experiments on two popular summarization datasets \u0026ndash; CNN/DM and XSum \u0026ndash; we show that our approach vastly outperforms prior methods in correcting erroneous summaries. Our model \u0026ndash; FactEdit \u0026ndash; improves factuality scores by over ~11 points on CNN/DM and over ~31 points on XSum on average across multiple summarization models, producing more factual summaries while maintaining competitive summarization quality.\n","date":1665385200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665385200,"objectID":"f3f7f9af7c94d2fcc87a54f34b1c351b","permalink":"https://vidhishanair.github.io/project/factedit/","publishdate":"2022-10-10T00:00:00-07:00","relpermalink":"/project/factedit/","section":"project","summary":"Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models.","tags":["Text Summarization","Language Generation","Factuality","Reliable Generation","Infilling Language Models"],"title":"Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling","type":"project"},{"authors":["_Vidhisha Balachandran_","Hannaneh Hajishirzi","William Cohen","Yulia Tsvetkov"],"categories":null,"content":"","date":1665385200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665385200,"objectID":"eeb3db1a08df7d6cc6bd9da3f89cc892","permalink":"https://vidhishanair.github.io/publication/factedit/","publishdate":"2022-10-10T00:00:00-07:00","relpermalink":"/publication/factedit/","section":"publication","summary":"","tags":[],"title":"Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling","type":"publication"},{"authors":[],"categories":null,"content":"","date":1650092400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650092400,"objectID":"1a17eada47898ad460e4dd857d702bec","permalink":"https://vidhishanair.github.io/talk/transf/","publishdate":"2022-04-16T00:00:00-07:00","relpermalink":"/talk/transf/","section":"talk","summary":"","tags":[],"title":"Self Attention and Transformers for Undergrad NLP","type":"talk"},{"authors":null,"categories":null,"content":"Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods. We propose and analyze a simple, model-agnostic approach for incorporating KB paths into text-based QA systems and establish a strong upper bound on FQ for our method using an oracle retriever. We show that several variants of Personalized PageRank based fact retrievers lead to a low recall of answer entities and consequently fail to improve QA performance. Our results suggest that fact retrieval is a bottleneck for integrating KBs into real world QA datasets\n","date":1623308400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623308400,"objectID":"e59b88d52a9d855d62ced0520a25bae4","permalink":"https://vidhishanair.github.io/project/fatnq/","publishdate":"2021-06-10T00:00:00-07:00","relpermalink":"/project/fatnq/","section":"project","summary":"Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods.","tags":["Question Answering","KBQA","Natural Questions"],"title":"Investigating the Effect of Background Knowledge on Natural Questions","type":"project"},{"authors":[],"categories":null,"content":"","date":1622530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622530800,"objectID":"8886aec613285aec469dfc0b51192c4c","permalink":"https://vidhishanair.github.io/talk/realm/","publishdate":"2021-06-01T00:00:00-07:00","relpermalink":"/talk/realm/","section":"talk","summary":"Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it. Our best model, REALM++, incorporates all the best working findings and achieves significant QA accuracy improvements over baselines (~5.5% absolute accuracy) without any model design changes. Additionally, REALM++ matches the performance of large Open Domain QA models which have 3x more parameters demonstrating the efficiency of the setup.","tags":[],"title":"Simple and Efficient ways to Improve REALM","type":"talk"},{"authors":["_Vidhisha Balachandran_","Artidoro Pagnoni","Jay Yoon Lee","Dheeraj Rajagopal","Jaime Carbonell","Yulia Tsvetkov"],"categories":null,"content":"","date":1619852400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619852400,"objectID":"1d3b982d3c6ecfea72a025c5b6cefce4","permalink":"https://vidhishanair.github.io/publication/structsum/","publishdate":"2021-05-01T00:00:00-07:00","relpermalink":"/publication/structsum/","section":"publication","summary":"","tags":[],"title":"StructSum: Summarization via Structured Representations","type":"publication"},{"authors":[],"categories":null,"content":"","date":1619766000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619766000,"objectID":"646f78193515f21daf722588107b8bfe","permalink":"https://vidhishanair.github.io/talk/transp_summ/","publishdate":"2021-04-30T00:00:00-07:00","relpermalink":"/talk/transp_summ/","section":"talk","summary":"Internet users today have access to an ocean of information via the Web ranging from news articles to blogs to textbooks. To consume this ever-growing pool of information, the need for tools to concisely and accurately summarize important content from these sources is urgent. As data-driven NLP tools for automatic summarization are increasingly deployed as primary mediums for information consumption, they also become ripe for misuse by inadvertently propagating factual inaccuracies and overfitting to spurious data artifacts. Our work aims to build transparent and reliable tools for automatic summarization. This talk presents novel work toward building such methodologies. I will first introduce StructSum, an interpretable summarization framework that leverages the narrative structure of the document for producing higher quality summaries with reduced reliance on dataset artifacts. I will then present FRANK, a fine-grained factuality-focused evaluation benchmark that uses a  linguistically motivated typology to elicit human annotations on factual errors made by many state-of-art summarization models. We present a two-fold analysis: (i) we analyze various summarization models and present their strengths and weaknesses in producing factually consistent summaries and (ii) we test recent metrics proposed to evaluate factuality and present a fine-grained understanding of what kinds of errors they detect well. Finally, I will conclude with some thoughts on future directions of our work and the field of automatic summarization.","tags":[],"title":"On the Transparency and Reliability of Automatic Summarization","type":"talk"},{"authors":null,"categories":null,"content":"Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations, we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgment as well as their specific strengths and weaknesses.\n","date":1619506800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619506800,"objectID":"4e5bfc9ea7abab733901aa9adef0e5ec","permalink":"https://vidhishanair.github.io/project/frank/","publishdate":"2021-04-27T00:00:00-07:00","relpermalink":"/project/frank/","section":"project","summary":"Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets.","tags":["Summarization","Language Generation","Factuality","Typology Framework","Metrics"],"title":"Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics","type":"project"},{"authors":["Artidoro Pagnoni","_Vidhisha Balachandran_","Yulia Tsvetkov"],"categories":null,"content":"","date":1619506800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619506800,"objectID":"32b49c423a162b4abca999e5ee2cdea4","permalink":"https://vidhishanair.github.io/publication/frank/","publishdate":"2021-04-27T00:00:00-07:00","relpermalink":"/publication/frank/","section":"publication","summary":"","tags":[],"title":"Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics","type":"publication"},{"authors":["Dheeraj Rajagopal","_Vidhisha Balachandran_","Eduard Hovy","Yulia Tsvetkov"],"categories":null,"content":"","date":1619161200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619161200,"objectID":"9e87a192a5ffcd2608a64c2dde008c17","permalink":"https://vidhishanair.github.io/publication/selfexplain/","publishdate":"2021-04-23T00:00:00-07:00","relpermalink":"/publication/selfexplain/","section":"publication","summary":"","tags":[],"title":"SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers","type":"publication"},{"authors":null,"categories":null,"content":"Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it. Our best model, REALM++, incorporates all the best working findings and achieves significant QA accuracy improvements over baselines (~5.5% absolute accuracy) without any model design changes. Additionally, REALM++ matches the performance of large Open Domain QA models which have 3x more parameters demonstrating the efficiency of the setup.\n","date":1618729200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618729200,"objectID":"a548688b5a70880ef052837f912c7653","permalink":"https://vidhishanair.github.io/project/realm/","publishdate":"2021-04-18T00:00:00-07:00","relpermalink":"/project/realm/","section":"project","summary":"Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it.","tags":["Question Answering","Open Domain QA","Evaluation","REALM"],"title":"Simple and Efficient ways to Improve REALM","type":"project"},{"authors":["Rishabh Joshi","_Vidhisha Balachandran_","Shikhar Vashishth","Alan Black","Yulia Tsvetkov"],"categories":null,"content":"","date":1617260400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617260400,"objectID":"2449c489a268a7f196ffbf8608805ef1","permalink":"https://vidhishanair.github.io/publication/dialograph/","publishdate":"2021-04-01T00:00:00-07:00","relpermalink":"/publication/dialograph/","section":"publication","summary":"","tags":[],"title":"DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues","type":"publication"},{"authors":null,"categories":null,"content":"We introduce SelfExplain, a novel self-explaining framework that explains a text classifier\u0026rsquo;s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance. Most importantly, explanations from SelfExplain are perceived as more understandable, adequately justifying and trustworthy by human judges compared to existing widely-used baselines.\n","date":1616482800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616482800,"objectID":"297097d430af9942fa1de0fac97602f5","permalink":"https://vidhishanair.github.io/project/selfexplain/","publishdate":"2021-03-23T00:00:00-07:00","relpermalink":"/project/selfexplain/","section":"project","summary":"We introduce SelfExplain, a novel self-explaining framework that explains a text classifier\u0026rsquo;s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance.","tags":["Interpretability by Design","Interpretability","Self-Explaining Architectures","Text Classification"],"title":"SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers","type":"project"},{"authors":["_Vidhisha Balachandran_","Ashish Vaswani","Yulia Tsvetkov","Niki Parmar"],"categories":null,"content":"","date":1616050800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616050800,"objectID":"28732bbac54d5e94eb58e5434d3654e0","permalink":"https://vidhishanair.github.io/publication/realm/","publishdate":"2021-03-18T00:00:00-07:00","relpermalink":"/publication/realm/","section":"publication","summary":"","tags":[],"title":"Simple and Efficient ways to Improve REALM","type":"publication"},{"authors":["_Vidhisha Balachandran_","Bhuwan Dhingra","Haitian Sun","Michael Collins","William Cohen"],"categories":null,"content":"","date":1615363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615363200,"objectID":"5b662861b58d024192145ef3070c3cb6","permalink":"https://vidhishanair.github.io/publication/fatnq/","publishdate":"2021-03-10T00:00:00-08:00","relpermalink":"/publication/fatnq/","section":"publication","summary":"","tags":[],"title":"Investigating the Effect of Background Knowledge on Natural Questions","type":"publication"},{"authors":["Bhuwan Dhingra","Manzhil Zaheer","_Vidhisha Balachandran_","Graham Neubig","Ruslan Salakhutdinov","William Cohen"],"categories":null,"content":"","date":1604214000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604214000,"objectID":"743fb1c33df1b57da503114683ea4a6e","permalink":"https://vidhishanair.github.io/publication/diffindex/","publishdate":"2020-11-01T00:00:00-07:00","relpermalink":"/publication/diffindex/","section":"publication","summary":"","tags":[],"title":"Differentiable Reasoning over a Virtual Knowledge Base","type":"publication"},{"authors":null,"categories":null,"content":"To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context. Our graph-based method outperforms prior state-of-the-art negotiation models both in the accuracy of strategy/dialogue act prediction and in the quality of downstream dialogue response generation. We qualitatively show further benefits of learned strategy-graphs in providing explicit associations between effective negotiation strategies over the course of the dialogue, leading to interpretable and strategic dialogues.\n","date":1601276400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601276400,"objectID":"abd334ff702d43dd62bf8a23cd914cd7","permalink":"https://vidhishanair.github.io/project/dialograph/","publishdate":"2020-09-28T00:00:00-07:00","relpermalink":"/project/dialograph/","section":"project","summary":"To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context.","tags":["Negotiation Dialog","Language Generation","Graph Neural Networks","Interpretability"],"title":"DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues","type":"project"},{"authors":null,"categories":null,"content":"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations. This module is differentiable, so the full system can be trained completely end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the index mention encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. DrKIT is also very efficient, processing upto 10x more queries per second than existing state-of-the-art QA systems.\n","date":1576224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576224000,"objectID":"e1a7127e7d74ffe9de53260fc4a625bb","permalink":"https://vidhishanair.github.io/project/vkb/","publishdate":"2019-12-13T00:00:00-08:00","relpermalink":"/project/vkb/","section":"project","summary":"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations.","tags":["Question Answering","Multi-Hop QA","Deep Learning","Knowledge Bases","Information Extraction","Data Structures for QA"],"title":"Differentiable Reasoning over a Virtual Knowledge Base","type":"project"},{"authors":null,"categories":null,"content":"","date":1551513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551513600,"objectID":"be216eba72bdfd73641f42586edd3781","permalink":"https://vidhishanair.github.io/project/entity/","publishdate":"2019-03-02T00:00:00-08:00","relpermalink":"/project/entity/","section":"project","summary":"Developing models for entity recognition and entity linking for closed domain data. Building classifiers to learn and predict cases of fraud in the insurance domain. Developing machine learning models for fraud detection in a low resource domain","tags":[],"title":"Closed Domain Entity Recognition and Fraud Detection","type":"project"},{"authors":["_Vidhisha Balachandran_","Dheeraj Rajagopal","Rose Catherine","William Cohen"],"categories":null,"content":"","date":1541055600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541055600,"objectID":"60e1382df5f64dbb888d1e0f8ae5c90e","permalink":"https://vidhishanair.github.io/publication/defgen/","publishdate":"2018-11-01T00:00:00-07:00","relpermalink":"/publication/defgen/","section":"publication","summary":"","tags":[],"title":"Learning to Define Terms in the Software Domain","type":"publication"},{"authors":null,"categories":null,"content":"Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges. To this end, we propose incorporating latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. Our framework complements standard encoder-decoder summarization models by augmenting them with rich structure-aware document representations based on implicitly learned (latent) structures and externally-derived linguistic (explicit) structures. We show that our summarization framework, trained on the CNN/DM dataset, improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines.\n","date":1539327600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539327600,"objectID":"7d8671b39588934e6643cc6644f565fc","permalink":"https://vidhishanair.github.io/project/structsum/","publishdate":"2018-10-12T00:00:00-07:00","relpermalink":"/project/structsum/","section":"project","summary":"Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges.","tags":["Text Summarization","Language Generation","Latent/Explicit Document Structure","Interpretability","Interpretable Structures"],"title":"StructSum: Summarization via Structured Representations","type":"project"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536476400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536476400,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://vidhishanair.github.io/tutorial/example/","publishdate":"2018-09-09T00:00:00-07:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":null,"categories":null,"content":"","date":1527404400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527404400,"objectID":"0d31a0bf9f48884bbb83f4c192477fc7","permalink":"https://vidhishanair.github.io/project/tabletotext/","publishdate":"2018-05-27T00:00:00-07:00","relpermalink":"/project/tabletotext/","section":"project","summary":"Built a Seq2Seq model for generating biographies of people from Wikipedia Biography Tables. Used alignments between table and text phrases to improve biographies. Results were on par with the previous State of Art models","tags":["Table to Text Generation","Language Generation"],"title":"Table to Text Generation","type":"project"},{"authors":null,"categories":null,"content":"One way to test a person’s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information. Our approach improves previous baselines by 2 BLEU points for the definition generation task. Our experiments also show the additional challenges associated with the task and the short-comings of language-model based architectures for definition generation.\n","date":1512374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512374400,"objectID":"33178e6d6db0122b02e6994acbf56928","permalink":"https://vidhishanair.github.io/project/defgen/","publishdate":"2017-12-04T00:00:00-08:00","relpermalink":"/project/defgen/","section":"project","summary":"One way to test a person’s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information.","tags":["Sequence Generation","Language Generation","Word Embeddings"],"title":"Definition Generation","type":"project"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461135600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515830400,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://vidhishanair.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00-07:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://vidhishanair.github.io/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]