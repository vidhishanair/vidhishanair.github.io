<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vidhisha Balachandran on Vidhisha Balachandran</title>
    <link>https://vidhishanair.github.io/</link>
    <description>Recent content in Vidhisha Balachandran on Vidhisha Balachandran</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Vidhisha Balachandran 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Experience</title>
      <link>https://vidhishanair.github.io/experience/experience/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://vidhishanair.github.io/experience/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating the Effect of Background Knowledge on Natural Questions</title>
      <link>https://vidhishanair.github.io/project/fatnq/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/fatnq/</guid>
      <description>&lt;p&gt;Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods. We propose and analyze a simple, model-agnostic approach for incorporating KB paths into text-based QA systems and establish a strong upper bound on FQ for our method using an oracle retriever. We show that several variants of Personalized PageRank based fact retrievers lead to a low recall of answer entities and consequently fail to improve QA performance. Our results suggest that fact retrieval is a bottleneck for integrating KBs into real world QA datasets&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigating the Effect of Background Knowledge on Natural Questions</title>
      <link>https://vidhishanair.github.io/publication/fatnq/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/publication/fatnq/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simple and Efficient ways to Improve REALM</title>
      <link>https://vidhishanair.github.io/talk/realm/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/talk/realm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Transparency and Reliability of Automatic Summarization</title>
      <link>https://vidhishanair.github.io/talk/transp_summ/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/talk/transp_summ/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</title>
      <link>https://vidhishanair.github.io/project/frank/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/frank/</guid>
      <description>&lt;p&gt;Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations, we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgment as well as their specific strengths and weaknesses.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</title>
      <link>https://vidhishanair.github.io/publication/frank/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/publication/frank/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simple and Efficient ways to Improve REALM</title>
      <link>https://vidhishanair.github.io/project/realm/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/realm/</guid>
      <description>&lt;p&gt;Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it. Our best model, REALM++, incorporates all the best working findings and achieves significant QA accuracy improvements over baselines (~5.5% absolute accuracy) without any model design changes. Additionally, REALM++ matches the performance of large Open Domain QA models which have 3x more parameters demonstrating the efficiency of the setup.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simple and Efficient ways to Improve REALM</title>
      <link>https://vidhishanair.github.io/publication/realm/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/publication/realm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers</title>
      <link>https://vidhishanair.github.io/project/selfexplain/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/selfexplain/</guid>
      <description>&lt;p&gt;We introduce SelfExplain, a novel self-explaining framework that explains a text classifier&amp;rsquo;s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance. Most importantly, explanations from SelfExplain are perceived as more understandable, adequately justifying and trustworthy by human judges compared to existing widely-used baselines.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers</title>
      <link>https://vidhishanair.github.io/publication/selfexplain/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/publication/selfexplain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues</title>
      <link>https://vidhishanair.github.io/project/dialograph/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/dialograph/</guid>
      <description>&lt;p&gt;To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context. Our graph-based method outperforms prior state-of-the-art negotiation models both in the accuracy of strategy/dialogue act prediction and in the quality of downstream dialogue response generation. We qualitatively show further benefits of learned strategy-graphs in providing explicit associations between effective negotiation strategies over the course of the dialogue, leading to interpretable and strategic dialogues.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues</title>
      <link>https://vidhishanair.github.io/publication/dialograph/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/publication/dialograph/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differentiable Reasoning over a Virtual Knowledge Base</title>
      <link>https://vidhishanair.github.io/project/vkb/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 -0500</pubDate>
      
      <guid>https://vidhishanair.github.io/project/vkb/</guid>
      <description>&lt;p&gt;We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations. This module is differentiable, so the full system can be trained completely end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the index mention encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. DrKIT is also very efficient, processing upto 10x more queries per second than existing state-of-the-art QA systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Closed Domain Entity Recognition and Fraud Detection</title>
      <link>https://vidhishanair.github.io/project/entity/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 -0500</pubDate>
      
      <guid>https://vidhishanair.github.io/project/entity/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
