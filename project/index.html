

<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.1.1">
  <meta name="generator" content="Hugo 0.51" />
  <meta name="author" content="Vidhisha Balachandran">

  
  
  
  
    
  
  <meta name="description" content="Graduate Student at Language Technologies Institute">

  
  <link rel="alternate" hreflang="en-us" href="https://vidhishanair.github.io/project/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=family=Work+Sans">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://vidhishanair.github.io/project/index.xml" type="application/rss+xml" title="Vidhisha Balachandran">
  <link rel="feed" href="https://vidhishanair.github.io/project/index.xml" type="application/rss+xml" title="Vidhisha Balachandran">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://vidhishanair.github.io/project/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Vidhisha Balachandran">
  <meta property="og:url" content="https://vidhishanair.github.io/project/">
  <meta property="og:title" content="Projects | Vidhisha Balachandran">
  <meta property="og:description" content="Graduate Student at Language Technologies Institute">
  
  
    
  <meta property="og:image" content="https://vidhishanair.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2023-05-18T00:00:00-07:00">
  

  

  

  <title>Projects | Vidhisha Balachandran</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header fixed-top">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Vidhisha Balachandran</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#experience">
            
            <span>Experience</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#talks">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/files/cv.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

      

        

        

        
      </ul>

    </div>
  </div>
</nav>















  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1 itemprop="name">Projects</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
  <div>
    <h2><a href="/project/cook/">CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge</a></h2>
    <div class="article-style">
      
      Large language models (LLMs) are increasingly adopted for knowledge-intensive tasks and contexts. Existing approaches improve the knowledge capabilities of general-purpose LLMs through retrieval or generated knowledge prompting, but they fall short of reflecting two key properties of knowledge-rich models: knowledge should be modular, ever-growing, sourced from diverse domains; knowledge acquisition and production should be a collaborative process, where diverse stakeholders contribute new information. To this end, we propose CooK, a novel framework to empower general-purpose large language models with modular and collaboratively sourced knowledge.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/factkb/">FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge</a></h2>
    <div class="article-style">
      
      Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/harms_survey/">Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey</a></h2>
    <div class="article-style">
      
      Recent advances in the capacity of large language models to generate human-like text have resulted in their increased adoption in user-facing settings. In parallel, these improvements have prompted a heated discourse around the risks of societal harms they introduce, whether inadvertent or malicious. Several studies have identified potential causes of these harms and called for their mitigation via development of safer and fairer models. Going beyond enumerating the risks of harms, this work provides a survey of practical methods for addressing potential threats and societal harms from language generation models.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/inspect/">Unsupervised Keyphrase Extraction via Interpretable Neural Networks</a></h2>
    <div class="article-style">
      
      Keyphrase extraction aims at automatically extracting a list of ``important&rdquo; phrases representing the key concepts in a document. Prior approaches for unsupervised keyphrase extraction resort to heuristic notions of phrase importance via embedding similarities or graph centrality, requiring extensive domain expertise to develop them. Our work presents an alternative operational definition: phrases that are most useful for predicting the topic of a text are keyphrases. To this end, we propose INSPECT&mdash;a self-explaining neural framework for identifying influential keyphrases by measuring the predictive impact of input phrases on the downstream task of topic classification.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/factedit/">Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling</a></h2>
    <div class="article-style">
      
      Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/lexplain/">LEXplain: Improving Model Explanations via Lexicon Supervision</a></h2>
    <div class="article-style">
      
      Model explanations that shed light on the model{&lsquo;}s predictions are becoming a desired additional output of NLP models, alongside their predictions. Challenges in creating these explanations include making them trustworthy and faithful to the model{&rsquo;}s predictions. In this work, we propose a novel framework for guiding model explanations by supervising them explicitly. To this end, our method, LEXplain, uses task-related lexicons to directly supervise model explanations. This approach consistently improves the model{&lsquo;}s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/fatnq/">Investigating the Effect of Background Knowledge on Natural Questions</a></h2>
    <div class="article-style">
      
      Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/frank/">Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</a></h2>
    <div class="article-style">
      
      Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/realm/">Simple and Efficient ways to Improve REALM</a></h2>
    <div class="article-style">
      
      Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it.
      
    </div>
  </div>
  
  <div>
    <h2><a href="/project/selfexplain/">SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers</a></h2>
    <div class="article-style">
      
      We introduce SelfExplain, a novel self-explaining framework that explains a text classifier&rsquo;s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance.
      
    </div>
  </div>
  

  
<nav>
  <ul class="pagination justify-content-center">
    
    
    <li class="page-item"><a class="page-link" href="/project/page/2/">&raquo;</a></li>
    
  </ul>
</nav>


</div>
<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; Vidhisha Balachandran 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    

    
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.74b0d3361475b08c40cf31120e82937b.js"></script>

    

  </body>
</html>



