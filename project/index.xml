<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Vidhisha Balachandran</title>
    <link>https://vidhishanair.github.io/project/</link>
    <description>Recent content in Projects on Vidhisha Balachandran</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Vidhisha Balachandran 2018</copyright>
    <lastBuildDate>Thu, 10 Jun 2021 00:00:00 -0700</lastBuildDate><atom:link href="https://vidhishanair.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Investigating the Effect of Background Knowledge on Natural Questions</title>
      <link>https://vidhishanair.github.io/project/fatnq/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/fatnq/</guid>
      <description>Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods.</description>
    </item>
    
    <item>
      <title>Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</title>
      <link>https://vidhishanair.github.io/project/frank/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/frank/</guid>
      <description>Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets.</description>
    </item>
    
    <item>
      <title>Simple and Efficient ways to Improve REALM</title>
      <link>https://vidhishanair.github.io/project/realm/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/realm/</guid>
      <description>Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it.</description>
    </item>
    
    <item>
      <title>DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues</title>
      <link>https://vidhishanair.github.io/project/dialograph/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/dialograph/</guid>
      <description>To successfully negotiate a deal, it is not enough to communicate fluently: pragmatic planning of persuasive negotiation strategies is essential. While modern dialogue agents excel at generating fluent sentences, they still lack pragmatic grounding and cannot reason strategically. We present DialoGraph, a negotiation system that incorporates pragmatic strategies in a negotiation dialogue using graph neural networks. DialoGraph explicitly incorporates dependencies between sequences of strategies to enable improved and interpretable prediction of next optimal strategies, given the dialogue context.</description>
    </item>
    
    <item>
      <title>Differentiable Reasoning over a Virtual Knowledge Base</title>
      <link>https://vidhishanair.github.io/project/vkb/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 -0800</pubDate>
      
      <guid>https://vidhishanair.github.io/project/vkb/</guid>
      <description>We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations.</description>
    </item>
    
    <item>
      <title>Closed Domain Entity Recognition and Fraud Detection</title>
      <link>https://vidhishanair.github.io/project/entity/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 -0800</pubDate>
      
      <guid>https://vidhishanair.github.io/project/entity/</guid>
      <description>Developing models for entity recognition and entity linking for closed domain data. Building classifiers to learn and predict cases of fraud in the insurance domain. Developing machine learning models for fraud detection in a low resource domain</description>
    </item>
    
    <item>
      <title>StructSum: Summarization via Structured Representations</title>
      <link>https://vidhishanair.github.io/project/structsum/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/structsum/</guid>
      <description>Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges.</description>
    </item>
    
    <item>
      <title>Table to Text Generation</title>
      <link>https://vidhishanair.github.io/project/tabletotext/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/tabletotext/</guid>
      <description>Built a Seq2Seq model for generating biographies of people from Wikipedia Biography Tables. Used alignments between table and text phrases to improve biographies. Results were on par with the previous State of Art models</description>
    </item>
    
    <item>
      <title>Definition Generation</title>
      <link>https://vidhishanair.github.io/project/defgen/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 -0800</pubDate>
      
      <guid>https://vidhishanair.github.io/project/defgen/</guid>
      <description>One way to test a personâ€™s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information.</description>
    </item>
    
  </channel>
</rss>
