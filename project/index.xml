<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Vidhisha Balachandran</title>
    <link>https://vidhishanair.github.io/project/</link>
    <description>Recent content in Projects on Vidhisha Balachandran</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Vidhisha Balachandran 2018</copyright>
    <lastBuildDate>Tue, 23 Mar 2021 00:00:00 -0400</lastBuildDate>
    
	<atom:link href="https://vidhishanair.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SelfExplain: A Self-Explaining Architecture for Neural Text Classifiers</title>
      <link>https://vidhishanair.github.io/project/structsum/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/structsum/</guid>
      <description>Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges.</description>
    </item>
    
    <item>
      <title>Differentiable Reasoning over a Virtual Knowledge Base</title>
      <link>https://vidhishanair.github.io/project/vkb/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 -0500</pubDate>
      
      <guid>https://vidhishanair.github.io/project/vkb/</guid>
      <description>We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations.</description>
    </item>
    
    <item>
      <title>Closed Domain Entity Recognition and Fraud Detection</title>
      <link>https://vidhishanair.github.io/project/entity/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 -0500</pubDate>
      
      <guid>https://vidhishanair.github.io/project/entity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>StructSum: Summarization via Structured Representations</title>
      <link>https://vidhishanair.github.io/project/selfexplain/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/selfexplain/</guid>
      <description>Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges.</description>
    </item>
    
    <item>
      <title>Table to Text Generation</title>
      <link>https://vidhishanair.github.io/project/tabletotext/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 -0400</pubDate>
      
      <guid>https://vidhishanair.github.io/project/tabletotext/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Definition Generation</title>
      <link>https://vidhishanair.github.io/project/defgen/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>https://vidhishanair.github.io/project/defgen/</guid>
      <description>One way to test a personâ€™s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information.</description>
    </item>
    
  </channel>
</rss>