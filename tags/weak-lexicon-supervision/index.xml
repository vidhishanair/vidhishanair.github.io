<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Weak Lexicon Supervision on Vidhisha Balachandran</title>
    <link>https://vidhishanair.github.io/tags/weak-lexicon-supervision/</link>
    <description>Recent content in Weak Lexicon Supervision on Vidhisha Balachandran</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Vidhisha Balachandran 2018</copyright>
    <lastBuildDate>Sat, 10 Jul 2021 00:00:00 -0700</lastBuildDate>
    
	<atom:link href="https://vidhishanair.github.io/tags/weak-lexicon-supervision/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>LEXplain: Improving Model Explanations via Lexicon Supervision</title>
      <link>https://vidhishanair.github.io/project/lexplain/</link>
      <pubDate>Sat, 10 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/lexplain/</guid>
      <description>Model explanations that shed light on the model{&amp;lsquo;}s predictions are becoming a desired additional output of NLP models, alongside their predictions. Challenges in creating these explanations include making them trustworthy and faithful to the model{&amp;rsquo;}s predictions. In this work, we propose a novel framework for guiding model explanations by supervising them explicitly. To this end, our method, LEXplain, uses task-related lexicons to directly supervise model explanations. This approach consistently improves the model{&amp;lsquo;}s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection.</description>
    </item>
    
  </channel>
</rss>