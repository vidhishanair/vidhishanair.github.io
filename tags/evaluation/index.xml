<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Evaluation on Vidhisha Balachandran</title>
    <link>https://vidhishanair.github.io/tags/evaluation/</link>
    <description>Recent content in Evaluation on Vidhisha Balachandran</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Vidhisha Balachandran 2018</copyright>
    <lastBuildDate>Sun, 18 Apr 2021 00:00:00 -0700</lastBuildDate>
    
	<atom:link href="https://vidhishanair.github.io/tags/evaluation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Simple and Efficient ways to Improve REALM</title>
      <link>https://vidhishanair.github.io/project/realm/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/realm/</guid>
      <description>Dense retrieval has been shown to be effective for retrieving relevant documents for Open Domain QA, surpassing popular sparse retrieval methods like BM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that relies on MLM based pretraining for improved downstream QA efficiency across multiple datasets. We study the finetuning of REALM on various QA tasks and explore the limits of various hyperparameter and supervision choices. We find that REALM was significantly undertrained when finetuning and simple improvements in the training, supervision, and inference setups can significantly benefit QA results and exceed the performance of other models published post it.</description>
    </item>
    
  </channel>
</rss>