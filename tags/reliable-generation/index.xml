<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reliable Generation on Vidhisha Balachandran</title>
    <link>https://vidhishanair.github.io/tags/reliable-generation/</link>
    <description>Recent content in Reliable Generation on Vidhisha Balachandran</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Vidhisha Balachandran 2018</copyright>
    <lastBuildDate>Thu, 18 May 2023 00:00:00 -0700</lastBuildDate>
    
	<atom:link href="https://vidhishanair.github.io/tags/reliable-generation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge</title>
      <link>https://vidhishanair.github.io/project/cook/</link>
      <pubDate>Thu, 18 May 2023 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/cook/</guid>
      <description>Large language models (LLMs) are increasingly adopted for knowledge-intensive tasks and contexts. Existing approaches improve the knowledge capabilities of general-purpose LLMs through retrieval or generated knowledge prompting, but they fall short of reflecting two key properties of knowledge-rich models: knowledge should be modular, ever-growing, sourced from diverse domains; knowledge acquisition and production should be a collaborative process, where diverse stakeholders contribute new information. To this end, we propose CooK, a novel framework to empower general-purpose large language models with modular and collaboratively sourced knowledge.</description>
    </item>
    
    <item>
      <title>FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge</title>
      <link>https://vidhishanair.github.io/project/factkb/</link>
      <pubDate>Thu, 18 May 2023 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/factkb/</guid>
      <description>Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases.</description>
    </item>
    
    <item>
      <title>Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling</title>
      <link>https://vidhishanair.github.io/project/factedit/</link>
      <pubDate>Mon, 10 Oct 2022 00:00:00 -0700</pubDate>
      
      <guid>https://vidhishanair.github.io/project/factedit/</guid>
      <description>Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models.</description>
    </item>
    
  </channel>
</rss>