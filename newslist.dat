
**[21/01/24]** Check out 2 new preprints on [Fine-Grained Hallucination in LLMs](https://arxiv.org/abs/2401.06855) and [Preserving Perspectives in News Summarization](https://arxiv.org/abs/2311.09741).
**[18/01/24]** Our paper [Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models](https://arxiv.org/abs/2305.09955) was accepted to ICLR 2024 as an Oral! See you in Vienna!
**[12/01/23]** Gave a talk on [Understanding and Mitigating Factual Inconsistencies in Language Generation](/talk/dlct/) at the [ML Collective - Deep Learning: Classics and Trends Reading Group](https://mlcollective.org/dlct/)! Thank you for having me!
**[07/10/23]** Our paper [FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge](https://arxiv.org/abs/2305.08281) was accepted to EMNLP (Main Conference) 2023.
**[28/08/23]** Excited to be selected as an [EECS Rising Star 2023](https://eecsrisingstars2023.cc.gatech.edu/participants/Vidhisha_Balachandran/)!
**[09/07/23]** Attending ACL 2023 to present [LEXplain](https://aclanthology.org/2023.starsem-1.19/) at *SEM 2023.
**[20/06/23]** Gave a talk on [Reporting and Mitigating Language Model Harms](/talk/georgetown/) at the Center for Security and Emerging Technology at Georgetown University!
**[16/06/23]** Our paper'LEXplain: Improving Model Explanations via Lexicon Supervision' was accepted to *SEM.
**[18/05/23]** Gave a talk on [Generalizable Factual Error Correction](/talk/semafor/) at the DARPA SemaFor group!
**[05/05/23]** Presented our survey paper on [Mitigating LM Risks](https://arxiv.org/abs/2210.07700) at EACL 2023.
**[17/04/23]** Proposed my thesis on 'Designing Transparent and Factual Text Generation Systems Grounded in Linguistic Structures'.
**[21/01/23]** 2 papers accepted to EACL 2023!
